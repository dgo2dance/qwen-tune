{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RomxmJkjnqE",
        "outputId": "b904a602-6266-4cc4-9223-55bde2ee7b60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Dec 10 02:30:51 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check GPU configuration\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vu-XmSvFj1gg"
      },
      "source": [
        "#STEP 0 確認有使用GPU\n",
        "##記事本必須在GPU模式下運行，可以執行上方的nvidia-smi查看GPU是否有GPU。若没有，點擊左上角的 編輯>筆記本設定，把硬體加速器改成GPU。\n",
        "##如記事本有出問題可在以下儲存庫回報\n",
        "> https://github.com/ADT109119/LLaMA-Factory-Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2PYE5UE4cCc"
      },
      "outputs": [],
      "source": [
        "#@title STEP 1 複製儲存庫並安裝必要的函式庫\n",
        "#@markdown #STEP 1\n",
        "#@markdown ##複製儲存庫並安裝必要的函式庫\n",
        "#@markdown ##Clone repository & Install requirements lib\n",
        "\n",
        "!git clone https://github.com/hiyouga/LLaMA-Factory.git\n",
        "%cd ./LLaMA-Factory\n",
        "!pip install -r requirements.txt\n",
        "!pip install bitsandbytes>=0.39.0\n",
        "\n",
        "#用比較殘暴的方式開啟 Gradio 的分享連結\n",
        "train_web_py_file_path = \"./src/train_web.py\"\n",
        "try:\n",
        "  with open(train_web_py_file_path, 'r') as file:\n",
        "    file_content = file.read()\n",
        "  modified_content = file_content.replace(\"share=False\", \"share=True\")\n",
        "  with open(train_web_py_file_path, 'w') as file:\n",
        "    file.write(modified_content)\n",
        "except Exception as e:\n",
        "    print(f'ERROR: {str(e)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiFJX0-d6thC"
      },
      "outputs": [],
      "source": [
        "#@title STEP 2 開啟WebUI\n",
        "#@markdown #STEP 2\n",
        "#@markdown ##開啟WebUI\n",
        "#@markdown ##Run the WebUI\n",
        "\n",
        "!CUDA_VISIBLE_DEVICES=0 python src/train_web.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I11rZlhctzd9"
      },
      "source": [
        "#STEP 3 上傳輸出的檔案到 HuggingFace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rte6fcaejOsC"
      },
      "outputs": [],
      "source": [
        "#@title STEP 3.1 安裝HuggingFace API\n",
        "#@markdown #STEP 3.1\n",
        "#@markdown ##為了上傳模型至HuggingFace，需要先安裝HF的函式庫\n",
        "#@markdown ##In order to upload the model to HuggingFace, we have to install the HF library first.\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRbS8HBWTZpu"
      },
      "outputs": [],
      "source": [
        "#@title STEP 3.2 使用API Token登入\n",
        "#@markdown #STEP 3.2\n",
        "#@markdown ##執行本儲存格後填入 API Token(需要有 Write 權限)，然後按下登入\n",
        "#@markdown ##After runing this cell, fill in the API Token (Write permission is required), and then click Login\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd7sv-ZvT4KB"
      },
      "outputs": [],
      "source": [
        "#@title STEP 3.3 上傳模型\n",
        "#@markdown #STEP 3.3\n",
        "#@markdown ##執行本儲存格後填入 API Token(需要有 Write 權限)，然後按下登入\n",
        "#@markdown ##After runing this cell, fill in the API Token (Write permission is required), and then click Login\n",
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "model_id = \"username/fine-tune-model\" #@param {type:\"string\"}\n",
        "export_folder_path = \"/content/LLaMA-Factory/export\" #@param {type:\"string\"}\n",
        "api.create_repo(model_id, private=True, exist_ok=True, repo_type=\"model\")\n",
        "api.upload_folder(\n",
        "    folder_path=export_folder_path,\n",
        "    repo_id=model_id,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7VH8k-s0G71"
      },
      "source": [
        "#STEP 4 保存到Google Drive(自選)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2StL2Wqt0MAt"
      },
      "outputs": [],
      "source": [
        "#@title STEP 4.1 連接Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72nLh_L50g74"
      },
      "outputs": [],
      "source": [
        "#@title STEP 4.2 複製檔案到Google Drive\n",
        "Google_Drive_Folder = \"/content/drive/MyDrive/LLaMA-Factory/\" #@param {type:\"string\"}\n",
        "\n",
        "!cp -rf /content/LLaMA-Factory/saves {Google_Drive_Folder}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}